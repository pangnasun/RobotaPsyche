
#### March 31st Reaing Assignment
#### Discussion Topics 
- [Steffen Steinert's "The Five Robots—A Taxonomy for Roboethics"](https://github.com/michaelshiloh/resourcesForClasses/blob/master/doc/theFiveRobotsATaxonomyForRoboethics.pdf).
1. **Status as a person:** "In the past, blacks, gypsies, children, women, foreigners, corporations, prisoners, and Jews have been regarded at some points in history as being legal non-persons" (Steiner 252). Are we repeating the "past" by considering/labeling/defining robots as non-persons or robots are a completely different case? Steinert mentions how "societies 'make' persons, because persons are 'produced' by a process of personification, which is conferring the status of a person to something" (252). Since "being a person" is defined as a status made by the society to bestow on a person, couldn't we do the same thing to robots? Of course, the following-up question would be: is a certain robot deemed worthy enough to receive that honor and how do we determine a robot's worthiness? Should robots undergo to be certified as "persons"?
2. **Robots' Roles and Responsiblities/Accountabilities:** Steinert mentions a variety of robots, ranging from vacuum bots and combat robots (254) to babysitting and eldercaring robots (255), and points out how their levels of autonomy and roles are different from each other. Could we use robots' roles and levels of autonomy as the basis to evaluate how responsible are they for their actions? A robot with more freedom to create its own decisions should be held accountable or more accountable than a robot with semi-autonomy. Still, engineers and programmers are the one who implements robots' roles and "ethical standards and routines" (254) that govern their autonomy. So, should we take this into consideration as well?
3. **Steinert's Meta Perspective:** "They \[ethicists] don’t hesitate to evaluate the influence of robots in particular niches such as medical care and the “social impact of intelligent artifacts” [35]. But they hardly illuminate the various forms of influence that robotics has on ethics itself" (256). What are "the various forms of influence robotics has on ethics itself"? What are the various forms of influence ethics has on robotics? I agree with Steinert that these two main fields must work together to create comprehsenive guidelines for roboethics, but I do not completely understand all his points like the role of anthropomorphism and how robotics influences ethics. 

- [David Levy's "The Ethical Treatment of Artificially Conscious Robots"](https://github.com/michaelshiloh/resourcesForClasses/blob/master/doc/theEthicalTreatmentOfArtificiallyConsciousRobots.pdf).
4. **Robots and Children:** Both articles bring up relations between robots and children quite frequently. For instance, Steinert talks about how children "conceiving of and treating AIBO \[dog robot] socially in some ways as if it were a real dog" (252-253). In "The Ethical Treatment of Artificially Conscious Robots," Levy points ouf the following: 
     >If our children see it as acceptable behaviour from their parents to scream and shout at a robot or to hit it, then, despite the fact that we can program   
     >robots to feel no such pain or unhappiness, our children might well come to accept that such behaviour is acceptable in the treatment of human beings. By 
     >virtue of their exhibiting consciousness, robots will come to be perceived by many humans, and especially by children, as being in some sense on the same 
     >plane as humans.(214)      

Both authors seem to agree that children perceive robots as capable of receiving social treatments. What makes those children see robots that way? Shouldn't we consider their lack of their experience or is their lack of experience the reason why they are chosen to do the experiment? Why are they focusing so much on children's perception of robots? 
In addition, Levy compares robots to children several times in his article. For example, argues why robots shoudl not be people's slaves even although people create them just like " we ought not enslave children even though they owe us their very existence and their ability to think" (212). Could we make such comparision? Are children and slaves that alike? Do creators and their robots have the same attachment/relation/connection as parents to their children? 

5. **The Author's Bias:** I couldn't but feel that Levy is biased regarding robots' rights and legal stance; he is strongly favoring robots, and I found some of his evidence not convincing. For example, when trying to proving the validity of the delay test, he uses the follwoing argument: 
>> While it is simple to create a computer program that passes \[the test], such success does not suggest anything beyond a clever programmer.” \[18]. I beg to                      differ. The fact that a clever programmer is responsible for creating artificial consciousness in a robot is surely no argument for denying that the robot exhibits consciousness. Ask any devout Christian the question: “Who programmed us to behave as we do?” and you will quite likely be told that we are pro- grammed by God. Does that mean that we do not possess consciousness? (211 - 212) 
 I see his point, but I feel unsettling because are we talking about the same thing when bringing out religion, belief, and, especially, God? I don't see how his  
 argument eliminates the doubt that programmers could program robots to pass any tests. In addition, Levy seems to make an assumption that robots are like human 
 beings in the first place,like when comparing robots to children and robots as having consciousness. And is it alright to skip discussing or defining consciousness 
 completely?

